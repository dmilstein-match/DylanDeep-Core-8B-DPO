Yes, your understanding is spot-on, and the advice you quoted is correct. Collecting rollouts for RL (especially 8 trajectories per question on the Abel dataset ≈ 1,980 questions × 8 = ~15,840 long math solutions) is inherently slow and low-utilization if done naively.
Here are the best practical ways to speed it up dramatically (from 2–4 hours → 10–40 minutes), ranked by impact/effort:








































MethodExpected SpeedupEffortGPU UtilizationRecommendation1. Switch to vLLM4–10×Low70–95%⭐⭐⭐⭐⭐ Best choice2. Batched generation (even with HF) + multi-GPU + separate files3–6×Medium40–80%⭐⭐⭐⭐ Good if you can’t use vLLM3. Reduce trajectories per question (e.g. from 8 → 4)~2×NoneSame⭐⭐ Quick & dirty4. Sample only a subset of Abel questions for initial experimentsUp to 10×NoneSame⭐⭐ For testing
Option 1: Switch to vLLM (Strongly Recommended)
This is by far the biggest win. vLLM with paged attention is designed exactly for this use case.
How to do it in your repo (assuming you’re using something like DeepSeek-Math-8B or Qwen2-Math-7B):
Bash# Install vLLM (do this once)
pip install vllm==0.6.3.post1  # or latest

# Then replace your collect_rollouts_abel.py with something like this (minimal changes):
accelerate launch --multi_gpu --num_processes=8 src/rl_training/collect_rollouts_abel_vllm.py
You’ll need a small script like this (you can copy-paste and adjust paths):
Python# src/rl_training/collect_rollouts_abel_vllm.py
from vllm import LLM, SamplingParams
from datasets import load_from_disk
import json, os

model_name = "checkpoints/abel_sft_lora_merged"  # or your base + peft path if you merge first
llm = LLM(model=model_name, tensor_parallel_size=int(os.environ.get("WORLD_SIZE", "1")), max_model_len=8192)

sampling_params = SamplingParams(
    temperature=0.7,
    top_p=0.95,
    max_tokens=2048,
    stop=["<|endoftext|>"]  # adjust if needed
)

dataset = load_from_disk("data/abel_dataset")["train"]

outputs = []
for batch in dataset.iter(batch_size=32):  # vLLM will batch these automatically across all GPUs
    prompts = [example["prompt"] for example in batch]  # whatever your prompt format is
    generations = llm.generate(prompts, sampling_params)
    for prompt, gen in zip(prompts, generations):
        outputs.append({
            "prompt": prompt,
            "completion": gen.outputs[0].text,
            # add metadata if needed
        })

    if len(outputs) % 100 == 0:
        print(f"Generated {len(outputs)} rollouts")

# Each rank writes its own file
rank = int(os.environ.get("RANK", 0))
with open(f"data/abel_regime_w_rollouts_part{rank}.jsonl", "w") as f:
    for out in outputs:
        f.write(json.dumps(out) + "\n")
→ You’ll get 8 files, then just cat part* > abel_regime_w_rollouts.jsonl at the end.
This will saturate all 8 GPUs at 80–95% utilization and finish in ~15–30 minutes instead of hours.