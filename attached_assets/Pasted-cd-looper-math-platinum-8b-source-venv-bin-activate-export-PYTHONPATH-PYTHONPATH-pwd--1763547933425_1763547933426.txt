cd ~/looper-math-platinum-8b
source .venv/bin/activate
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

pip install flash-attn --upgrade

python - << 'EOF'
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import load_dataset
import torch
import json
from tqdm import tqdm
from src.regime_w.arms import build_all_arms
from src.regime_w.reward import compute_rewards_for_question

model_path = "checkpoints/abel_sft_merged_fixed"
dataset = load_dataset("json", data_files="data/gsm8k_train.jsonl", split="train")

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
    low_cpu_mem_usage=True,
    attn_implementation="flash_attention_2"  # Faster inference
)
tokenizer = AutoTokenizer.from_pretrained(model_path)

outfile = "data/abel_regime_w_rollouts.jsonl"
open(outfile, "w").close()

arms = build_all_arms()  # 8 arms

batch_size = 64  # 8 arms x 8 per arm = 64
total = len(dataset)

outputs = []

with tqdm(total=total, desc="Processing questions") as pbar:
    for i in range(len(dataset)):
        question = dataset[i]["question"]
        gold_answer = dataset[i]["answer"]

        batch_prompts = []
        for arm in arms:
            styled_prompt = arm.apply(question)
            batch_prompts.extend([styled_prompt] * (batch_size // len(arms)))

        inputs = tokenizer(batch_prompts, return_tensors="pt", padding=True).to(model.device)

        with torch.no_grad():
            gen = model.generate(
                **inputs,
                max_new_tokens=2048,
                temperature=0.7,
                do_sample=True,
                top_p=0.95
            )

        texts = tokenizer.batch_decode(gen, skip_special_tokens=True)

        trajectories = [{"full_text": text.strip()} for text in texts]
        rewarded_trajectories = compute_rewards_for_question(question, gold_answer, trajectories)

        outputs.append({
            "question": question,
            "gold_answer": gold_answer,
            "trajectories": rewarded_trajectories
        })
        pbar.update(1)

        if len(outputs) % 50 == 0:
            with open(outfile, "a") as f:
                for out in outputs:
                    f.write(json.dumps(out) + "\n")
            outputs = []

# Final write
with open(outfile, "a") as f:
    for out in outputs:
        f.write(json.dumps(out) + "\n")

print("DONE â€” FULL 15,840 ROLLOUTS WITH REWARDS")
EOF